{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a79f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define arms\n",
    "def quick_sort(df,columns):\n",
    "    sorted_df = df.sort_values(columns,kind=\"quicksort\")\n",
    "    return sorted_df\n",
    "def merge_sort(df,columns):\n",
    "    sorted_df = df.sort_values(columns,kind=\"mergesort\")\n",
    "    return sorted_df\n",
    "def heap_sort(df,columns):\n",
    "    sorted_df = df.sort_values(columns,kind=\"heapsort\")\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8205e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [quick_sort,merge_sort,heap_sort]\n",
    "choices_names = [\"quick_sort\",\"merge_sort\",\"heap_sort\"]\n",
    "dist_types = [\"Uniform\",\"Normal\",\"Uniform_Sorted\",\"Uniform_Reverse_Sorted\",\"Uniform_Nearly_Sorted\",\"Zipf\", \"Dates\", \"Strings\", \"Discrete_Uniform\", \"Discrete_Binomial\", \"Poisson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31328ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different number of samples for different experiments\n",
    "n_samples_1e5 = 100000\n",
    "n_samples_5e4 = 50000\n",
    "n_samples_5e5 = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "548c1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the settings of  the 5 different experimental set-ups\n",
    "list_distributions_1 = 1000*[\"Discrete_Uniform\"] + 1000*[\"Uniform_Sorted\"] \n",
    "# list_distributions_1 with n_samples_1e5\n",
    "list_distributions_2 = 50*[\"Discrete_Uniform\"] +  50*[\"Uniform_Sorted\"]  \n",
    "# list_distributions_2 with n_samples_5e5\n",
    "list_distributions_3 = 1000*[\"Discrete_Uniform\"] +  1000*[\"Uniform_Sorted\"] + 1000*[\"Discrete_Binomial\"] + 1000*[\"Uniform_Reverse_Sorted\"]\n",
    "# list_distributions_3 with n_samples_5e4\n",
    "list_distributions_4 = 100*[\"Uniform_Sorted\"] +  50*[\"Poisson\"] + 100*[\"Uniform_Reverse_Sorted\"] + 50*[\"Zipf\"]\n",
    "# list_distributions_4 with n_samples_1e5\n",
    "list_distributions_5 = 50*[\"Uniform_Sorted\"] +  50*[\"Poisson\"] + 50*[\"Uniform_Reverse_Sorted\"] + 50*[\"Zipf\"] +  50*[\"Uniform_Reverse_Sorted\"] + 50*[\"Discrete_Uniform\"]\n",
    "# list_distributions_5 with n_samples_1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b1e529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards_distribution_together(arm_rewards, bins = 20):\n",
    "    for key in arm_rewards:    \n",
    "        arm_rewards[key] = [i * (-1) for i in arm_rewards[key]]\n",
    "    #arm_rewards[\"quick_sort\"] = arm_rewards[\"quick_sort\"]*(-1)\n",
    "    #arm_rewards[\"merge_sort\"] = arm_rewards[\"merge_sort\"]*(-1)\n",
    "    #arm_rewards[\"heap_sort\"] = arm_rewards[\"heap_sort\"]*(-1)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    _, bin_edges_qs = np.histogram(arm_rewards[\"quick_sort\"], density=True)\n",
    "    _, bin_edges_ms = np.histogram(arm_rewards[\"merge_sort\"], density=True)\n",
    "    _, bin_edges_hs = np.histogram(arm_rewards[\"heap_sort\"], density=True)\n",
    "    plt.hist(arm_rewards[\"quick_sort\"], bins=bin_edges_qs, alpha = 0.5, label='quick sort')\n",
    "    plt.hist(arm_rewards[\"merge_sort\"], bins=bin_edges_ms, alpha = 0.5, label='merge sort')\n",
    "    plt.hist(arm_rewards[\"heap_sort\"], bins=bin_edges_hs, alpha = 0.5, label='heap sort')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5) ,fontsize=26)\n",
    "    plt.title(\"Distribution of runtimes during experiment\",fontsize=26)\n",
    "    plt.ylabel(\"Frequency\",fontsize=26)\n",
    "    plt.xlabel(\"Runtime in seconds\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05e8c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(rewards,cum_rewards,chosen_arms):\n",
    "    print(\"Arm Counts\", chosen_arms)\n",
    "    fig = plt.figure(figsize=[16,6])\n",
    "    ax2 = fig.add_subplot(121)\n",
    "    ax2.plot(cum_rewards, label=\"avg rewards\")\n",
    "    ax2.set_title(\"Cummulative Rewards\",fontsize=18)\n",
    "    ax2.set_ylabel('Reward (multiplied by -1)',fontsize=16)\n",
    "    ax2.set_xlabel('Iteration',fontsize=16)\n",
    "    plt.setp(ax2.get_xticklabels(), fontsize=14)\n",
    "    plt.setp(ax2.get_yticklabels(), fontsize=14)\n",
    "    labels = list(chosen_arms.keys())\n",
    "    ax3 = fig.add_subplot(122)\n",
    "    ax3.bar(chosen_arms.keys(), chosen_arms.values())\n",
    "    ax3.set_title(\"Chosen Actions\",fontsize=18)\n",
    "    ax3.set_ylabel('Frequency',fontsize=16)\n",
    "    ax3.set_xlabel('Action',fontsize=16)\n",
    "    plt.setp(ax3.get_xticklabels(), fontsize=14)\n",
    "    plt.setp(ax3.get_yticklabels(), fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f23f17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_iterations_1(history, restarts=None):\n",
    "    df = pd.DataFrame.from_records(history,columns=[\"Iteration\",\"Reward\",\"Algorithm\"])\n",
    "    df[\"Reward\"] = df[\"Reward\"]*(-1)\n",
    "    groups = df.groupby('Algorithm')\n",
    "    # Plot\n",
    "    mean_1 = (pd.read_csv(\"DATA/df_discrete_uniform_100000.csv\")).quicksort.mean()\n",
    "    mean_2 = (pd.read_csv(\"DATA/df_uniform_sorted_100000.csv\")).mergesort.mean()\n",
    "    x_values_1 = [0, 999]\n",
    "    y_values_1 = [mean_1,mean_1]\n",
    "    x_values_2 = [1000, 2000]\n",
    "    y_values_2 = [mean_2,mean_2]\n",
    "    dict_colors = {\"quick_sort\":'#1f77b4', \"merge_sort\":'#ff7f0e', \"heap_sort\":'#2ca02c'}\n",
    "    plt.figure(figsize=(16,6))\n",
    "    for name, group in groups:\n",
    "        plt.plot(group.Iteration, group.Reward, marker='o', linestyle='', ms=10, alpha = 0.5, label=name, color=dict_colors[name])\n",
    "    plt.plot(x_values_1, y_values_1, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, label=\"Optimal Solution Quick Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_2, y_values_2, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, label=\"Optimal Solution Merge Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    if restarts != None:\n",
    "        for i, point in enumerate(restarts):\n",
    "            if not i:\n",
    "                plt.axvline(x=point, color=\"red\", label=\"Restart\")\n",
    "            else:\n",
    "                plt.axvline(x=point, color=\"red\")\n",
    "    \n",
    "    plt.legend(fontsize=26, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.title(\"Algorithm choices during experiment\",fontsize=26)\n",
    "    plt.ylabel(\"Runtime in seconds\",fontsize=26)\n",
    "    plt.xlabel(\"Iteration\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18bfa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_iterations_2(history, restarts=None):\n",
    "    df = pd.DataFrame.from_records(history,columns=[\"Iteration\",\"Reward\",\"Algorithm\"])\n",
    "    df[\"Reward\"] = df[\"Reward\"]*(-1)\n",
    "    groups = df.groupby('Algorithm')\n",
    "    mean_1 = (pd.read_csv(\"DATA/df_discrete_uniform_500000.csv\")).quicksort.mean()\n",
    "    mean_2 = (pd.read_csv(\"DATA/df_uniform_sorted_500000.csv\")).mergesort.mean()\n",
    "    x_values_1 = [0, 49]\n",
    "    y_values_1 = [mean_1,mean_1]\n",
    "    x_values_2 = [50, 100]\n",
    "    y_values_2 = [mean_2,mean_2]\n",
    "    dict_colors = {\"quick_sort\":'#1f77b4', \"merge_sort\":'#ff7f0e', \"heap_sort\":'#2ca02c'}\n",
    "    plt.figure(figsize=(16,6))\n",
    "    for name, group in groups:\n",
    "        plt.plot(group.Iteration, group.Reward, marker='o', linestyle='', ms=10, alpha = 0.5, label=name, color=dict_colors[name])\n",
    "    plt.plot(x_values_1, y_values_1, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, label=\"Optimal Solution Quick Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_2, y_values_2, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, label=\"Optimal Solution Merge Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    \n",
    "    if restarts != None:\n",
    "        for i, point in enumerate(restarts):\n",
    "            if not i:\n",
    "                plt.axvline(x=point, color=\"red\", label=\"Restart\")\n",
    "            else:\n",
    "                plt.axvline(x=point, color=\"red\")\n",
    "    \n",
    "    plt.legend(fontsize=26, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.title(\"Algorithm choices during experiment\",fontsize=26)\n",
    "    plt.ylabel(\"Runtime in seconds\",fontsize=26)\n",
    "    plt.xlabel(\"Iteration\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b5eec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_iterations_3(history,restarts=None):\n",
    "    df = pd.DataFrame.from_records(history,columns=[\"Iteration\",\"Reward\",\"Algorithm\"])\n",
    "    df[\"Reward\"] = df[\"Reward\"]*(-1)\n",
    "    groups = df.groupby('Algorithm')\n",
    "    # Plot\n",
    "    mean_1 = (pd.read_csv(\"DATA/df_discrete_uniform_50000.csv\")).quicksort.mean()\n",
    "    mean_2 = (pd.read_csv(\"DATA/df_uniform_sorted_50000.csv\")).mergesort.mean()\n",
    "    mean_3 = (pd.read_csv(\"DATA/df_discrete_binomial_50000.csv\")).quicksort.mean()\n",
    "    mean_4 = (pd.read_csv(\"DATA/df_uniform_reverse_sorted_50000.csv\")).mergesort.mean()\n",
    "    x_values_1 = [0, 999]\n",
    "    y_values_1 = [mean_1,mean_1]\n",
    "    x_values_2 = [1000, 1999]\n",
    "    y_values_2 = [mean_2,mean_2]\n",
    "    x_values_3 = [2000, 2999]\n",
    "    y_values_3 = [mean_3,mean_3]\n",
    "    x_values_4 = [3000, 4000]\n",
    "    y_values_4 = [mean_4,mean_4]\n",
    "    dict_colors = {\"quick_sort\":'#1f77b4', \"merge_sort\":'#ff7f0e', \"heap_sort\":'#2ca02c'}\n",
    "    plt.figure(figsize=(16,6))\n",
    "    for name, group in groups:\n",
    "        plt.plot(group.Iteration, group.Reward, marker='o', linestyle='', ms=10, alpha = 0.5, label=name, color=dict_colors[name])\n",
    "    plt.plot(x_values_1, y_values_1, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, label=\"Optimal Solution Quick Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_2, y_values_2, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, label=\"Optimal Solution Merge Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_3, y_values_3, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_4, y_values_4, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    \n",
    "    if restarts != None:\n",
    "        for i, point in enumerate(restarts):\n",
    "            if not i:\n",
    "                plt.axvline(x=point, color=\"red\", label=\"Restart\")\n",
    "            else:\n",
    "                plt.axvline(x=point, color=\"red\")\n",
    "                \n",
    "    plt.legend(fontsize=26, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.title(\"Algorithm choices during experiment\",fontsize=26)\n",
    "    plt.ylabel(\"Runtime in seconds\",fontsize=26)\n",
    "    plt.xlabel(\"Iteration\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4be5e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_iterations_4(history,restarts=None):\n",
    "    df = pd.DataFrame.from_records(history,columns=[\"Iteration\",\"Reward\",\"Algorithm\"])\n",
    "    df[\"Reward\"] = df[\"Reward\"]*(-1)\n",
    "    groups = df.groupby('Algorithm')\n",
    "    # Plot\n",
    "    mean_1 = (pd.read_csv(\"DATA/df_uniform_sorted_100000.csv\")).mergesort.mean()\n",
    "    mean_2 = (pd.read_csv(\"DATA/df_poisson_100000.csv\")).quicksort.mean()\n",
    "    mean_3 = (pd.read_csv(\"DATA/df_uniform_reverse_sorted_100000.csv\")).mergesort.mean()\n",
    "    mean_4 = (pd.read_csv(\"DATA/df_zipf_100000.csv\")).quicksort.mean()\n",
    "    x_values_1 = [0, 99]\n",
    "    y_values_1 = [mean_1,mean_1]\n",
    "    x_values_2 = [100, 149]\n",
    "    y_values_2 = [mean_2,mean_2]\n",
    "    x_values_3 = [150, 249]\n",
    "    y_values_3 = [mean_3,mean_3]\n",
    "    x_values_4 = [250, 300]\n",
    "    y_values_4 = [mean_4,mean_4]\n",
    "    dict_colors = {\"quick_sort\":'#1f77b4', \"merge_sort\":'#ff7f0e', \"heap_sort\":'#2ca02c'}\n",
    "    plt.figure(figsize=(16,6))\n",
    "    for name, group in groups:\n",
    "        plt.plot(group.Iteration, group.Reward, marker='o', linestyle='', ms=10, alpha = 0.5, label=name, color=dict_colors[name])\n",
    "    \n",
    "    if restarts != None:\n",
    "        for i, point in enumerate(restarts):\n",
    "            if not i:\n",
    "                plt.axvline(x=point, color=\"red\", label=\"Restart\")\n",
    "            else:\n",
    "                plt.axvline(x=point, color=\"red\")\n",
    "    plt.plot(x_values_1, y_values_1, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, label=\"Optimal Solution Merge Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_2, y_values_2, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, label=\"Optimal Solution Quick Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_3, y_values_3, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_4, y_values_4, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.legend(fontsize=26, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.title(\"Algorithm choices during experiment\",fontsize=26)\n",
    "    plt.ylabel(\"Runtime in seconds\",fontsize=26)\n",
    "    plt.xlabel(\"Iteration\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa14a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_iterations_5(history,restarts=None):\n",
    "    df = pd.DataFrame.from_records(history,columns=[\"Iteration\",\"Reward\",\"Algorithm\"])\n",
    "    df[\"Reward\"] = df[\"Reward\"]*(-1)\n",
    "    groups = df.groupby('Algorithm')\n",
    "    # Plot\n",
    "    mean_1 = (pd.read_csv(\"DATA/df_uniform_sorted_100000.csv\")).mergesort.mean()\n",
    "    mean_2 = (pd.read_csv(\"DATA/df_poisson_100000.csv\")).quicksort.mean()\n",
    "    mean_3 = (pd.read_csv(\"DATA/df_uniform_reverse_sorted_100000.csv\")).mergesort.mean()\n",
    "    mean_4 = (pd.read_csv(\"DATA/df_zipf_100000.csv\")).quicksort.mean()\n",
    "    mean_5 = (pd.read_csv(\"DATA/df_uniform_reverse_sorted_100000.csv\")).mergesort.mean()\n",
    "    mean_6 = (pd.read_csv(\"DATA/df_discrete_uniform_100000.csv\")).quicksort.mean()\n",
    "    x_values_1 = [0, 49]\n",
    "    y_values_1 = [mean_1,mean_1]\n",
    "    x_values_2 = [50, 99]\n",
    "    y_values_2 = [mean_2,mean_2]\n",
    "    x_values_3 = [100, 149]\n",
    "    y_values_3 = [mean_3,mean_3]\n",
    "    x_values_4 = [150, 199]\n",
    "    y_values_4 = [mean_4,mean_4]\n",
    "    x_values_5 = [200, 249]\n",
    "    y_values_5 = [mean_5,mean_5]\n",
    "    x_values_6 = [250, 300]\n",
    "    y_values_6 = [mean_6,mean_6]\n",
    "    dict_colors = {\"quick_sort\":'#1f77b4', \"merge_sort\":'#ff7f0e', \"heap_sort\":'#2ca02c'}\n",
    "    plt.figure(figsize=(16,6))\n",
    "    for name, group in groups:\n",
    "        plt.plot(group.Iteration, group.Reward, marker='o', linestyle='', ms=10, alpha = 0.5, label=name, color=dict_colors[name])\n",
    "    if restarts != None:\n",
    "        for i, point in enumerate(restarts):\n",
    "            if not i:\n",
    "                plt.axvline(x=point, color=\"red\", label=\"Restart\")\n",
    "            else:\n",
    "                plt.axvline(x=point, color=\"red\")\n",
    "    plt.plot(x_values_1, y_values_1, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, label=\"Optimal Solution Merge Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_2, y_values_2, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, label=\"Optimal Solution Quick Sort\", path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_3, y_values_3, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_4, y_values_4, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_5, y_values_5, marker = 'o', markersize=10, color = '#ff7f0e', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.plot(x_values_6, y_values_6, marker = 'o', markersize=10, color = '#1f77b4', linewidth=1, path_effects= [mpe.Stroke(linewidth=3, foreground='black')], alpha = 0.5)\n",
    "    plt.legend(fontsize=26, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.title(\"Algorithm choices during experiment\",fontsize=26)\n",
    "    plt.ylabel(\"Runtime in seconds\",fontsize=26)\n",
    "    plt.xlabel(\"Iteration\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa7624bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection(list_distributions, n_samples):\n",
    "    total_reward = 0\n",
    "    num_choices = len(choices)\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\":[]} \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0} \n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    history = []\n",
    "    iteration = 0\n",
    "    for n, elem in enumerate(list_distributions):\n",
    "        dist_type = elem\n",
    "        distribion =  create_df_distribution(n_samples=n_samples, dist_type=dist_type)\n",
    "        alg = np.random.choice(choices) \n",
    "        #print(alg)\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(distribion,dist_type)\n",
    "        reward = (time.perf_counter() - start_time)*(-1)\n",
    "        #print(iteration, \":\", alg.__name__, np.round(reward,4))\n",
    "        total_reward += reward\n",
    "        arm_rewards[alg.__name__].append(reward)\n",
    "        arm_counts[alg.__name__] += 1\n",
    "        rewards.append(reward)\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,alg.__name__])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c333b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(list_distributions, n_samples, epsilon=0.01, constant_value=0.01):\n",
    "    print(\"Epsilon: \", epsilon, \"Constant value: \", constant_value)\n",
    "    total_reward = 0\n",
    "    num_choices = len(choices)\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\":[]} \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0} \n",
    "    q_values = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0} \n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    history = []\n",
    "    iteration = 0\n",
    "    for n, elem in enumerate(list_distributions):\n",
    "        dist_type = elem\n",
    "        distribion =  create_df_distribution(n_samples=n_samples, dist_type=dist_type)\n",
    "        alg = np.random.choice(choices) if np.random.random() < epsilon else choices[np.argmax(list(q_values.values()))]\n",
    "        #print(alg)\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(distribion,dist_type)\n",
    "        reward = (time.perf_counter() - start_time)*(-1)\n",
    "        #print(iteration, \":\", alg.__name__, np.round(reward,4))\n",
    "        total_reward += reward\n",
    "        arm_rewards[alg.__name__].append(reward)\n",
    "        arm_counts[alg.__name__] += 1\n",
    "        q_values[alg.__name__]  += constant_value*(reward-q_values[alg.__name__])\n",
    "        rewards.append(reward)\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,alg.__name__])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba19e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help function to return the humber of consecutive elements in a list \n",
    "def count_consec(listrand):\n",
    "    count=1\n",
    "    consec_list=[]\n",
    "    for i in range(len(listrand[:-1])):\n",
    "        if listrand[i]+1 == listrand[i+1]:\n",
    "            count+=1\n",
    "        else:\n",
    "            consec_list.append(count)\n",
    "            count=1\n",
    "\n",
    "    # Account for the last iteration\n",
    "    consec_list.append(count)     \n",
    "\n",
    "    return consec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20a95291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucb(list_distributions, n_samples, num_consec_elem=1, bound_const=0.001, quantile=0.025, list_length=5):\n",
    "    print(\"Number consecutive outliers:\", num_consec_elem, \"Quantile:\", quantile)\n",
    "    total_reward = 0\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    ucb_values = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    num_choices = len(choices)\n",
    "    bound_const = bound_const\n",
    "    n_consecutive_list = []\n",
    "    num_consec_elem = num_consec_elem\n",
    "    iter_num = 0\n",
    "    iteration = 0\n",
    "    history = []\n",
    "    number_of_restarts = 0\n",
    "    restarts = []\n",
    "    for n, elem in enumerate(list_distributions):\n",
    "        dist_type = elem\n",
    "        distribion = create_df_distribution(n_samples=n_samples, dist_type=dist_type)\n",
    "        for i in (choices_names):\n",
    "                if arm_counts_temp[i] > 0: \n",
    "                    average_reward = np.mean(arm_rewards_temp[i])\n",
    "                    #print(\"av_reward\", average_reward, \"for\", choices_names[i])\n",
    "                    delta_i = bound_const*math.sqrt(2 * math.log(iter_num) / arm_counts_temp[i])\n",
    "                    #print(\"delta_i\", delta_i, \"for\", choices_names[i])\n",
    "                    ucb_values[i] = average_reward + delta_i\n",
    "                elif arm_counts_temp[i] == 0:\n",
    "                    ucb_values[i] = 1e500\n",
    "        choice = max(ucb_values, key=ucb_values.get)\n",
    "        alg = choices[list(ucb_values.keys()).index(choice)]\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(distribion,dist_type)\n",
    "        exeuction_time = time.perf_counter() - start_time\n",
    "        #print(alg, exeuction_time)\n",
    "        reward = exeuction_time*(-1)\n",
    "        arm_rewards[choice].append(reward)\n",
    "        arm_rewards_temp[choice].append(reward)\n",
    "        arm_counts[choice] += 1\n",
    "        arm_counts_temp[choice] += 1\n",
    "        total_reward += reward\n",
    "        rewards.append(reward)\n",
    "        iter_num += 1\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        if len(arm_rewards_temp[choice])>list_length:\n",
    "            if reward < np.quantile(arm_rewards_temp[choice][:-1], quantile) or reward > np.quantile(arm_rewards_temp[choice][:-1], (1-quantile)):\n",
    "                n_consecutive_list.append(n)\n",
    "                if any(i >= num_consec_elem for i in count_consec(n_consecutive_list)):\n",
    "                    number_of_restarts += 1\n",
    "                    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "                    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "                    n_consecutive_list = []\n",
    "                    iter_num = 0\n",
    "                    restarts.append(iteration)\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,choice])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history, number_of_restarts, restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d907794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling(list_distributions, n_samples, num_consec_elem=1, var_multiplier=1, quantile=0.025, list_length=5):\n",
    "    print(\"Number consecutive outliers:\", num_consec_elem, \"Quantile:\", quantile)\n",
    "    total_reward = 0\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    ucb_values = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    sample_mean = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    sample_mean_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    sample_var = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    sample_var_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    num_choices = len(choices)\n",
    "    n_consecutive_list = []\n",
    "    num_consec_elem = num_consec_elem\n",
    "    iteration = 0\n",
    "    history = []\n",
    "    number_of_restarts = 0\n",
    "    restarts = []\n",
    "    for n, elem in enumerate(list_distributions):\n",
    "        dist_type = elem\n",
    "        distribion = create_df_distribution(n_samples=n_samples, dist_type=dist_type)\n",
    "        theta = {}\n",
    "        for i in (choices_names):\n",
    "            if arm_counts_temp[i] >= 2:\n",
    "                theta[i] = t.rvs(df=arm_counts_temp[i]-1,loc=sample_mean_temp[i],scale=np.sqrt(sample_var_temp[i]/arm_counts_temp[i])*var_multiplier)\n",
    "            else:\n",
    "                theta[i] = uniform.rvs(loc=-1, scale=2)\n",
    "        choice = max(theta, key=theta.get) \n",
    "        alg = choices[list(ucb_values.keys()).index(choice)]\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(distribion,dist_type)\n",
    "        exeuction_time = time.perf_counter() - start_time\n",
    "        reward = exeuction_time*(-1)\n",
    "        arm_rewards[choice].append(reward)\n",
    "        arm_rewards_temp[choice].append(reward)\n",
    "        arm_counts[choice] += 1\n",
    "        arm_counts_temp[choice] += 1\n",
    "        sample_mean[choice] = np.mean(arm_rewards[choice])\n",
    "        sample_mean_temp[choice] = np.mean(arm_rewards_temp[choice])\n",
    "        sample_var[choice] = np.var(arm_rewards[choice])\n",
    "        sample_var_temp[choice] = np.var(arm_rewards_temp[choice])\n",
    "        total_reward += reward\n",
    "        rewards.append(reward)\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        if len(arm_rewards_temp[choice])>list_length:\n",
    "            if reward < np.quantile(arm_rewards_temp[choice][:-1], quantile) or reward > np.quantile(arm_rewards_temp[choice][:-1], (1-quantile)):\n",
    "                n_consecutive_list.append(n)\n",
    "                if any(i >= num_consec_elem for i in count_consec(n_consecutive_list)):\n",
    "                    number_of_restarts += 1\n",
    "                    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "                    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "                    sample_mean_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "                    sample_var_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "                    n_consecutive_list = []\n",
    "                    restarts.append(iteration)\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,choice])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history, number_of_restarts, restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cbc6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visulaization purposes\n",
    "def replace_outlier(val, mean, std, const=5):\n",
    "    if val > mean + const*std:\n",
    "        return mean + const*std \n",
    "    elif val < mean - const*std:\n",
    "        return mean - const*std\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0abcc9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(data):\n",
    "    plt.figure(figsize=(24,6))\n",
    "    plt.plot(data.rolling(1024).mean(), label=\"CR863\")\n",
    "    plt.legend(fontsize=24, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.ylabel(\"Value\",fontsize=26)\n",
    "    plt.xlabel(\"Number of Observation\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cd66072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_real_data(data, col, n_chunks=200, epsilon=0.01, constant_value=0.9):\n",
    "    total_reward = 0\n",
    "    num_choices = len(choices)\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\":[]} \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0} \n",
    "    q_values = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0} \n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    history = []\n",
    "    iteration = 0\n",
    "    for n, chunk in enumerate(np.array_split(data, n_chunks)):\n",
    "        alg = np.random.choice(choices) if np.random.random() < epsilon else choices[np.argmax(list(q_values.values()))]\n",
    "        #print(alg)\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(chunk, col)\n",
    "        reward = (time.perf_counter() - start_time)*(-1)\n",
    "        #print(iteration, \":\", alg.__name__, np.round(reward,4))\n",
    "        total_reward += reward\n",
    "        arm_rewards[alg.__name__].append(reward)\n",
    "        arm_counts[alg.__name__] += 1\n",
    "        q_values[alg.__name__]  += constant_value*(reward-q_values[alg.__name__])\n",
    "        rewards.append(reward)\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,alg.__name__])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd25910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucb_real_data(data, col, n_chunks=200, num_consec_elem=3, bound_const=0.001, quantile=0.025, list_length=5):\n",
    "    print(\"Number consecutive outliers:\", num_consec_elem, \"Quantile:\", quantile)\n",
    "    total_reward = 0\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    ucb_values = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    num_choices = len(choices)\n",
    "    bound_const = bound_const\n",
    "    n_consecutive_list = []\n",
    "    num_consec_elem = num_consec_elem\n",
    "    iter_num = 0\n",
    "    iteration = 0\n",
    "    history = []\n",
    "    number_of_restarts = 0\n",
    "    restarts = []\n",
    "    for n, chunk in enumerate(np.array_split(data, n_chunks)):\n",
    "        for i in (choices_names):\n",
    "                if arm_counts_temp[i] > 0: \n",
    "                    average_reward = np.mean(arm_rewards_temp[i])\n",
    "                    #print(\"av_reward\", average_reward, \"for\", choices_names[i])\n",
    "                    delta_i = bound_const*math.sqrt(2 * math.log(iter_num) / arm_counts_temp[i])\n",
    "                    #print(\"delta_i\", delta_i, \"for\", choices_names[i])\n",
    "                    ucb_values[i] = average_reward + delta_i\n",
    "                elif arm_counts_temp[i] == 0:\n",
    "                    ucb_values[i] = 1e500\n",
    "        choice = max(ucb_values, key=ucb_values.get)\n",
    "        alg = choices[list(ucb_values.keys()).index(choice)]\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(chunk,col)\n",
    "        exeuction_time = time.perf_counter() - start_time\n",
    "        #print(alg, exeuction_time)\n",
    "        reward = exeuction_time*(-1)\n",
    "        arm_rewards[choice].append(reward)\n",
    "        arm_rewards_temp[choice].append(reward)\n",
    "        arm_counts[choice] += 1\n",
    "        arm_counts_temp[choice] += 1\n",
    "        total_reward += reward\n",
    "        rewards.append(reward)\n",
    "        iter_num += 1\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        if len(arm_rewards_temp[choice])>list_length:\n",
    "            if reward < np.quantile(arm_rewards_temp[choice][:-1], quantile) or reward > np.quantile(arm_rewards_temp[choice][:-1], (1-quantile)):\n",
    "                n_consecutive_list.append(n)\n",
    "                if any(i >= num_consec_elem for i in count_consec(n_consecutive_list)):\n",
    "                    number_of_restarts += 1\n",
    "                    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "                    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "                    n_consecutive_list = []\n",
    "                    iter_num = 0\n",
    "                    restarts.append(iteration)\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,choice])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history, number_of_restarts, restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6701ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling_real_data(data, col, n_chunks=200, num_consec_elem=3, var_multiplier=1, quantile=0.025, list_length=5):\n",
    "    print(\"Number consecutive outliers:\", num_consec_elem, \"Quantile:\", quantile)\n",
    "    total_reward = 0\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    ucb_values = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "    sample_mean = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    sample_mean_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    sample_var = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    sample_var_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    num_choices = len(choices)\n",
    "    n_consecutive_list = []\n",
    "    num_consec_elem = num_consec_elem\n",
    "    iteration = 0\n",
    "    history = []\n",
    "    number_of_restarts = 0\n",
    "    restarts = []\n",
    "    for n, chunk in enumerate(np.array_split(data, n_chunks)):\n",
    "        theta = {}\n",
    "        for i in (choices_names):\n",
    "            if arm_counts_temp[i] >= 2:\n",
    "                theta[i] = t.rvs(df=arm_counts_temp[i]-1,loc=sample_mean_temp[i],scale=np.sqrt(sample_var_temp[i]/arm_counts_temp[i])*var_multiplier)\n",
    "            else:\n",
    "                theta[i] = uniform.rvs(loc=-1, scale=2)\n",
    "        choice = max(theta, key=theta.get) \n",
    "        alg = choices[list(ucb_values.keys()).index(choice)]\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(chunk,col)\n",
    "        exeuction_time = time.perf_counter() - start_time\n",
    "        reward = exeuction_time*(-1)\n",
    "        arm_rewards[choice].append(reward)\n",
    "        arm_rewards_temp[choice].append(reward)\n",
    "        arm_counts[choice] += 1\n",
    "        arm_counts_temp[choice] += 1\n",
    "        sample_mean[choice] = np.mean(arm_rewards[choice])\n",
    "        sample_mean_temp[choice] = np.mean(arm_rewards_temp[choice])\n",
    "        sample_var[choice] = np.var(arm_rewards[choice])\n",
    "        sample_var_temp[choice] = np.var(arm_rewards_temp[choice])\n",
    "        total_reward += reward\n",
    "        rewards.append(reward)\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        if len(arm_rewards_temp[choice])>list_length:\n",
    "            if reward < np.quantile(arm_rewards_temp[choice][:-1], quantile) or reward > np.quantile(arm_rewards_temp[choice][:-1], (1-quantile)):\n",
    "                n_consecutive_list.append(n)\n",
    "                if any(i >= num_consec_elem for i in count_consec(n_consecutive_list)):\n",
    "                    number_of_restarts += 1\n",
    "                    arm_rewards_temp = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\": []}  \n",
    "                    arm_counts_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}  \n",
    "                    sample_mean_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "                    sample_var_temp = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0}\n",
    "                    n_consecutive_list = []\n",
    "                    restarts.append(iteration)\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,choice])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history, number_of_restarts, restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d96ae844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection_real_data(data,col, n_chunks=200):\n",
    "    total_reward = 0\n",
    "    num_choices = len(choices)\n",
    "    arm_rewards = {\"quick_sort\": [], \"merge_sort\": [], \"heap_sort\":[]} \n",
    "    arm_counts = {\"quick_sort\": 0, \"merge_sort\": 0, \"heap_sort\":0} \n",
    "    rewards = []\n",
    "    cum_rewards = []\n",
    "    history = []\n",
    "    iteration = 0\n",
    "    for chunk in np.array_split(data, n_chunks):\n",
    "        alg = np.random.choice(choices) \n",
    "        #print(alg)\n",
    "        start_time = time.perf_counter()\n",
    "        sorted_dist = alg(chunk,col)\n",
    "        reward = (time.perf_counter() - start_time)*(-1)\n",
    "        #print(iteration, \":\", alg.__name__, np.round(reward,4))\n",
    "        total_reward += reward\n",
    "        arm_rewards[alg.__name__].append(reward)\n",
    "        arm_counts[alg.__name__] += 1\n",
    "        rewards.append(reward)\n",
    "        cum_rewards.append(sum(rewards)/len(rewards))\n",
    "        iteration+=1\n",
    "        history.append([iteration, reward,alg.__name__])\n",
    "    return total_reward, arm_rewards, arm_counts, cum_rewards, rewards, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e437b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_iterations_real_data(history, restarts=None):\n",
    "    df = pd.DataFrame.from_records(history,columns=[\"Iteration\",\"Reward\",\"Algorithm\"])\n",
    "    mean = df[\"Reward\"].mean()\n",
    "    std_dev = df[\"Reward\"].std()\n",
    "    df[\"Reward\"] = df[\"Reward\"].map(lambda x: replace_outlier(x, mean, std_dev))\n",
    "    df[\"Reward\"] = df[\"Reward\"]*(-1)\n",
    "    groups = df.groupby('Algorithm')\n",
    "    # Plot\n",
    "    dict_colors = {\"quick_sort\":'#1f77b4', \"merge_sort\":'#ff7f0e', \"heap_sort\":'#2ca02c'}\n",
    "    plt.figure(figsize=(16,6))\n",
    "    for name, group in groups:\n",
    "        plt.plot(group.Iteration, group.Reward, marker='o', linestyle='', ms=10, alpha = 0.5, label=name, color=dict_colors[name])\n",
    "    \n",
    "    if restarts != None:\n",
    "        for i, point in enumerate(restarts):\n",
    "            if not i:\n",
    "                plt.axvline(x=point, color=\"red\", label=\"Restart\")\n",
    "            else:\n",
    "                plt.axvline(x=point, color=\"red\")\n",
    "                \n",
    "    plt.legend(fontsize=26, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.title(\"Algorithm choices during experiment\",fontsize=26)\n",
    "    plt.ylabel(\"Runtime in seconds\",fontsize=26)\n",
    "    plt.xlabel(\"Iteration\",fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd9327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
